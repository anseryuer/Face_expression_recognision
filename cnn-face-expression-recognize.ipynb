{"cells":[{"cell_type":"markdown","metadata":{},"source":["The dataset is on Kaggle\n","https://www.kaggle.com/datasets/msambare/fer2013"]},{"cell_type":"code","execution_count":114,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.8.0\n"]}],"source":["import numpy as np \n","import random\n","import pandas as pd \n","import os\n","import tensorflow as tf\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n","from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n","\n","\n","import cv2\n","from glob import glob\n","\n","import matplotlib.pyplot as plt\n","import math\n","%matplotlib inline\n","print(tf.__version__)"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["import os\n","def read(name1,tagnum):\n","    imgs=[]\n","    labels=[]\n","    for filename in os.listdir(name1):\n","        img = load_img(name1 + \"/\" + filename)\n","        img=np.array(img.convert(\"L\"))#48,48灰度图\n","        imgs.append(img)\n","        labels.append(tagnum)\n","    imgs=np.array(imgs)\n","    lables=np.array(labels)\n","    return(imgs,labels)\n","#result1,label1=read(\"kaggle/images/train/angry\",1)"]},{"cell_type":"markdown","metadata":{},"source":["1-angry\n","2-disgust\n","3-fear\n","4-happy\n","5-neutral\n","6-sad\n","7-surprise"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from tensorflow.keras.utils import to_categorical\n","train_images=[]\n","train_labels=[]\n","test_images=[]\n","test_labels=[]\n","'''\n","train_images=np.array(train_images)\n","train_labels=np.array(train_labels)\n","test_images=np.array(test_images)\n","test_labels=np.array(test_labels)\n","'''\n","train_dir=\"C:/Users/yutia/OneDrive/临时/elec/kaggle/images/train\"\n","val_dir=\"C:/Users/yutia/OneDrive/临时/elec/kaggle/images/validation\"\n","for foldernum in range(len(os.listdir(train_dir))):\n","    foldername=train_dir + \"/\" + os.listdir(train_dir)[foldernum]\n","    train_images.extend(read(foldername,foldernum)[0])\n","    train_labels.extend(read(foldername,foldernum)[1])\n","\n","for foldernum in range(len(os.listdir(val_dir))):\n","    foldername=val_dir + \"/\" + os.listdir(val_dir)[foldernum]\n","    #print(foldername)\n","    test_images.extend(read(foldername,foldernum)[0])\n","    test_labels.extend(read(foldername,foldernum)[1])"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[],"source":["train_images=np.array(train_images,dtype=object)\n","train_labels=np.array(train_labels,dtype=object)\n","test_images=np.array(test_images,dtype=object)\n","test_labels=np.array(test_labels,dtype=object)"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"data":{"text/plain":["(7066, 48, 48)"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["test_images.shape"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[],"source":["train_images = train_images.reshape((28821, 48, 48, 1))\n","train_images = train_images.astype('float32') / 255\n","\n","test_images = test_images.reshape((7066, 48, 48, 1))\n","test_images = test_images.astype('float32') / 255\n","\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"]},{"cell_type":"code","execution_count":122,"metadata":{},"outputs":[],"source":["from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation='relu'))\n","model.add(layers.Dense(7, activation='softmax'))"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_3 (Conv2D)           (None, 46, 46, 32)        320       \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 23, 23, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 21, 21, 64)        18496     \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 10, 10, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 8, 8, 64)          36928     \n","                                                                 \n"," flatten_1 (Flatten)         (None, 4096)              0         \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                262208    \n","                                                                 \n"," dense_3 (Dense)             (None, 7)                 455       \n","                                                                 \n","=================================================================\n","Total params: 318,407\n","Trainable params: 318,407\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":124,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       [1., 0., 0., ..., 0., 0., 0.],\n","       ...,\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 1.],\n","       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"]},"execution_count":124,"metadata":{},"output_type":"execute_result"}],"source":["test_labels"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","1802/1802 [==============================] - 6s 3ms/step - loss: 1.8170 - accuracy: 0.2480\n","Epoch 2/5\n","1802/1802 [==============================] - 5s 3ms/step - loss: 1.8137 - accuracy: 0.2486\n","Epoch 3/5\n","1802/1802 [==============================] - 5s 3ms/step - loss: 1.8127 - accuracy: 0.2486\n","Epoch 4/5\n","1802/1802 [==============================] - 5s 3ms/step - loss: 1.8126 - accuracy: 0.2486\n","Epoch 5/5\n","1802/1802 [==============================] - 5s 3ms/step - loss: 1.8124 - accuracy: 0.2486\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x21f5a8fd750>"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["model.compile(optimizer='rmsprop',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.fit(train_images, train_labels, epochs=50, batch_size=16)"]},{"cell_type":"code","execution_count":126,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["221/221 [==============================] - 0s 2ms/step - loss: 2.1185 - accuracy: 0.2583\n","901/901 [==============================] - 1s 2ms/step - loss: 1.8113 - accuracy: 0.2486\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","train_loss, train_acc = model.evaluate(train_images, train_labels)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"865d8b2eb28e274047ba64063dfb6a2aabf0dfec4905d304d7a76618dae6fdd4"}}},"nbformat":4,"nbformat_minor":4}
